{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style = 'text-align: center'>Week 02: Text Feature Extraction</h1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer, FeatureHasher\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>1. Loading Features From Dicts </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      " ['city=Dubai' 'city=London' 'city=San Francisco' 'temperature']\n",
      "\n",
      "Feature matrix:\n",
      " [[ 1.  0.  0. 33.]\n",
      " [ 0.  1.  0. 12.]\n",
      " [ 0.  0.  1. 18.]]\n"
     ]
    }
   ],
   "source": [
    "# data in dict\n",
    "data = [\n",
    "    {'city': 'Dubai', 'temperature': 33.},\n",
    "    {'city': 'London', 'temperature': 12.},\n",
    "    {'city': 'San Francisco', 'temperature': 18.},\n",
    "]\n",
    "\n",
    "# init DictVectorizer\n",
    "vect = DictVectorizer(sparse=True)     #sparse: đại diện cho ma trận thưa: chỉ lưu trữ những phần tử khác 0 và vị trí của nó\n",
    "\n",
    "# apply on data\n",
    "vectorized_data = vect.fit_transform(data)\n",
    "\n",
    "# vect learns keys in data and stores them in inited DictVectorizer\n",
    "print(\"Feature names:\\n\",vect.get_feature_names_out())         # get feature names\n",
    "print()\n",
    "print(\"Feature matrix:\\n\", vectorized_data.toarray())       # .toarray() giúp hiện ma trận đầy đủ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_entry = [{'category': ['thriller', 'drama'], 'year': 2003},\n",
    "               {'category': ['animation', 'family'], 'year': 2011},\n",
    "               {'year': 1974}]\n",
    "\n",
    "vectorized_movie = vect.fit_transform(movie_entry)\n",
    "print(vect.get_feature_names_out())\n",
    "vectorized_movie.toarray()\n",
    "\n",
    "\n",
    "test_data = {'category': ['thriller'],          # đặc trưng thriller có -> bật bit 1\n",
    "               'unseen_feature': '3'}           # đặc trưng unseen_feature không có -> bỏ qua\n",
    "\n",
    "# biến đổi dữ liệu test_data dựa trên đặc trưng đã học của movie_entry\n",
    "vect.transform(test_data).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos+1=PP', 'pos-1=NN', 'pos-2=DT', 'word+1=on', 'word-1=cat',\n",
       "       'word-2=the'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract Part of Speech\n",
    "pos_window = [\n",
    "    {\n",
    "        'word-2': 'the',        # word là từ\n",
    "        'pos-2': 'DT',          # pos (part of speech): từ loại của nó\n",
    "        'word-1': 'cat',\n",
    "        'pos-1': 'NN',\n",
    "        'word+1': 'on',\n",
    "        'pos+1': 'PP',\n",
    "    },\n",
    "    # in a real application one would extract many such dictionaries\n",
    "]\n",
    "\n",
    "vect = DictVectorizer()\n",
    "pos_vectorized = vect.fit_transform(pos_window)\n",
    "\n",
    "pos_vectorized.toarray()\n",
    "\n",
    "vect.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Feature Hashing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# tạo đối tượng feature cho từng token\n",
    "def token_features(token, part_of_speech):\n",
    "    if token.isdigit():     # nếu là token chữ số\n",
    "        yield \"numeric\"\n",
    "    else:                   # nếu là token chữ: đưa về lower -> thêm token & pos\n",
    "        yield \"token={}\".format(token.lower())      \n",
    "        yield \"token,pos={},{}\".format(token, part_of_speech)\n",
    "    \n",
    "    if token[0].isupper():      # kiểm tra chữ cái đầu in hoa\n",
    "        yield \"uppercase_initial\"\n",
    "    if token.isupper():\n",
    "        yield \"all_uppercase\"\n",
    "        \n",
    "    yield \"pos={}\".format(part_of_speech)       # in pos của nó\n",
    "    # cuối cùng nếu là số: thì token có \"numeric\" & \"pos\"\n",
    "    # cuối cùng nếu là chữ: \"token\", \"token,pos\", \"uppercase_initial\" (hoặc \"all_uppercase\"), \"pos\"\n",
    "\n",
    "corpus = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens = nltk.word_tokenize(corpus)\n",
    "pos_tagged = pos_tag(tokens)\n",
    "\n",
    "raw_X = (token_features(tok, pos) for tok, pos in pos_tagged)\n",
    "hasher = FeatureHasher(input_type='string', alternate_sign = True, )\n",
    "X = hasher.transform(raw_X)     # X có kích thước lớn do FeatureHasher sử dụng bộ nhớ tối đa để lưu trữ dữ liệu -> \n",
    "\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>3. The Bag of Words</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
