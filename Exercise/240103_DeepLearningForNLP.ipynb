{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h1 style = 'text-align: center'> <b>Week 06: Deep Learning For NLP</b> </h1>"]},{"cell_type":"markdown","metadata":{},"source":["- Mentee: Võ Nguyễn Hoàng Kim\n","- Mentee ID: 240103"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-19T06:51:17.390063Z","iopub.status.busy":"2024-10-19T06:51:17.389690Z","iopub.status.idle":"2024-10-19T06:51:19.372511Z","shell.execute_reply":"2024-10-19T06:51:19.371256Z","shell.execute_reply.started":"2024-10-19T06:51:17.390031Z"},"trusted":true},"outputs":[],"source":["!pip install underthesea\n","!pip install gensim\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","import re\n","import underthesea\n","from underthesea import word_tokenize\n","from underthesea import text_normalize\n","from gensim.models import Word2Vec\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from underthesea import text_normalize\n","from underthesea import word_tokenize\n","import torch.nn as nn\n"]},{"cell_type":"markdown","metadata":{},"source":["# <b>1. Load Data path file and Label</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:51:19.375462Z","iopub.status.busy":"2024-10-19T06:51:19.375052Z","iopub.status.idle":"2024-10-19T06:51:19.441676Z","shell.execute_reply":"2024-10-19T06:51:19.440743Z","shell.execute_reply.started":"2024-10-19T06:51:19.375419Z"},"trusted":true},"outputs":[],"source":["def load_data_path_and_label(base_dir):\n","    file_paths = []\n","    labels = []\n","    for category in os.listdir(base_dir):\n","        category_dir_path = os.path.join(base_dir, category)\n","        for text_file in os.listdir(category_dir_path):\n","            text_file_path = os.path.join(category_dir_path, text_file)\n","            # append data & correspoding label\n","            file_paths.append(text_file_path)\n","            labels.append(category)\n","    return file_paths, labels\n","\n","# get path of data txt and the label\n","base_dir = '/kaggle/input/vietnamese-news-text-classification-corpus/27_Topics/Train/new train'\n","file_paths, labels = load_data_path_and_label(base_dir)"]},{"cell_type":"markdown","metadata":{},"source":["# <b>2. Encoding Label</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:51:19.443330Z","iopub.status.busy":"2024-10-19T06:51:19.442956Z","iopub.status.idle":"2024-10-19T06:51:19.457412Z","shell.execute_reply":"2024-10-19T06:51:19.456547Z","shell.execute_reply.started":"2024-10-19T06:51:19.443287Z"},"trusted":true},"outputs":[],"source":["# encoding label\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(labels)"]},{"cell_type":"markdown","metadata":{},"source":["# <b>3. Preprocess</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T06:51:27.717254Z","iopub.status.busy":"2024-10-19T06:51:27.716499Z"},"trusted":true},"outputs":[],"source":["def read_text_file(file_path):\n","    encodings = ['utf-8', 'latin-1', 'windows-1252', 'utf-16']\n","    for enc in encodings:\n","        try:\n","            with open(file_path, 'r', encoding=enc) as file:\n","                return file.read()\n","        except (UnicodeDecodeError, FileNotFoundError):\n","            continue  # Nếu gặp lỗi, thử với mã hóa tiếp theo\n","    return None  # Trả về None nếu không thể đọc tệp\n","\n","\n","def preprocess_text(text_file):\n","    stop_words = read_text_file(\"/kaggle/input/vietnamese-stop-words/vietnamese-stopwords.txt\")\n","    \n","    text = text_file.lower()\n","    # normalize\n","    normalized_text = text_normalize(text)\n","    # remove stop words\n","    stop_words_pattern = r'\\b(?:' + '|'.join(map(re.escape, stop_words)) + r')\\b'\n","    cleaned_text = re.sub(stop_words_pattern, ' ', normalized_text)\n","    cleaned_text = ' '.join(cleaned_text.split())\n","    tokens = word_tokenize(cleaned_text)\n","    return tokens\n","\n","# Load dữ liệu và tiền xử lý\n","documents = [preprocess_text(read_text_file(file_path)) for file_path in file_paths]\n","\n","# Tạo mô hình Word2Vec với dữ liệu đã được token hóa\n","word2vec_model = Word2Vec(sentences=documents, vector_size=100, window=5, min_count=1, workers=4)\n","word2vec_model.save(\"word2vec.model\")\n","\n","# Hàm chuyển đổi một văn bản thành vector bằng cách lấy trung bình vector của các từ\n","def get_average_word2vec(tokens, model, vector_size):\n","    vectors = []\n","    for token in tokens:\n","        if token in model.wv:\n","            vectors.append(model.wv[token])\n","    if len(vectors) > 0:\n","        return np.mean(vectors, axis=0)\n","    else:\n","        return np.zeros(vector_size)"]},{"cell_type":"markdown","metadata":{},"source":["# <b>4. Create Dataset & DataLoader</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cập nhật TextDataset\n","class TextDataset(Dataset):\n","    def __init__(self, file_paths, labels, word2vec_model, vector_size=100):\n","        self.file_paths = file_paths\n","        self.labels = torch.tensor(labels, dtype=torch.long)\n","        self.word2vec_model = word2vec_model\n","        self.vector_size = vector_size\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, index):\n","        file_path = self.file_paths[index]\n","        text = read_text_file(file_path)\n","        tokens = preprocess_text(text)\n","        \n","        # Chuyển đổi văn bản thành vector\n","        word2vec_vector = get_average_word2vec(tokens, self.word2vec_model, self.vector_size)\n","        \n","        input_ids = torch.tensor(word2vec_vector, dtype=torch.float32)  # Chuyển thành tensor\n","        label = self.labels[index]\n","\n","        return {\n","            \"input_ids\": input_ids,\n","            \"label\": label\n","        }\n","\n","# Khởi tạo dataset và dataloader\n","dataset = TextDataset(file_paths, encoded_labels, word2vec_model)\n","train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# <b>5. Create Model</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class LSTMClassifier(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.5):\n","        super(LSTMClassifier, self).__init__()\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)  # Thêm một chiều cho batch\n","        lstm_out, _ = self.lstm(x)\n","        out = self.fc(lstm_out[:, -1, :])  # Lấy đầu ra cuối cùng từ LSTM\n","        return out\n","\n","def train_model(model, train_loader, criterion, optimizer, epochs=10):\n","    model.train()  # Đặt mô hình ở chế độ huấn luyện\n","    for epoch in range(epochs):\n","        print(f\"Epoch {epoch+1}/{epochs}\")\n","        running_loss = 0.0\n","        for batch in train_loader:\n","            optimizer.zero_grad()  # Đặt lại gradient\n","\n","            # Chuyển dữ liệu và nhãn sang GPU (nếu có)\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            # Forward pass\n","            outputs = model(input_ids)  # Dự đoán đầu ra từ mô hình\n","            loss = criterion(outputs, labels)  # Tính toán loss\n","\n","            # Backward pass và tối ưu hóa\n","            loss.backward()  # Tính gradient\n","            optimizer.step()  # Cập nhật trọng số\n","\n","            running_loss += loss.item()  # Tính tổng loss\n","        print(f'Loss: {running_loss/len(train_loader):.4f}')  # In ra loss trung bình của mỗi epoch\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# <b>6. Train Model</b>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Khởi tạo mô hình với kích thước đầu vào phù hợp với Word2Vec\n","input_size = 100  # Kích thước vector của Word2Vec\n","hidden_size = 128\n","output_size = len(label_encoder.classes_)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Khởi tạo mô hình\n","model = LSTMClassifier(input_size, hidden_size, output_size)\n","\n","# Chuyển mô hình sang GPU nếu có\n","model = model.to(device)\n","\n","# Sử dụng CrossEntropyLoss cho bài toán phân loại\n","criterion = nn.CrossEntropyLoss()\n","\n","# Sử dụng Adam optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # lr là learning rate\n","\n","# Huấn luyện\n","train_model(model, train_dataloader, criterion, optimizer, epochs=10)\n","\n","# Lưu trọng số của mô hình\n","torch.save(model.state_dict(), '/kaggle/working/LSTM_model_word2vec_weights.pth')\n"]},{"cell_type":"markdown","metadata":{},"source":["# <b>7. Test Model</b>"]},{"cell_type":"markdown","metadata":{},"source":["## <b>a. Create Test data</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_path_dir = '/kaggle/input/vietnamese-news-text-classification-corpus/27_Topics/Test/new test'\n","test_file_paths, test_labels = load_data_path_and_label(test_path_dir)\n","test_documents = [preprocess_text(read_text_file(file_path)) for file_path in test_file_paths]\n","\n","# Khởi tạo dataset và dataloader cho dữ liệu kiểm thử\n","test_dataset = TextDataset(test_file_paths, test_labels, word2vec_model, test_documents)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"]},{"cell_type":"markdown","metadata":{},"source":["# <b>b. Test model</b>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_model(model, test_dataloader, criterion):\n","    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n","    total_loss = 0.0\n","    correct_predictions = 0\n","    total_samples = 0\n","\n","    with torch.no_grad():  # Không tính gradient khi kiểm thử\n","        for batch in test_dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['label'].to(device)\n","\n","            # Forward pass\n","            outputs = model(input_ids)\n","            loss = criterion(outputs, labels)\n","\n","            total_loss += loss.item()\n","\n","            # Lấy nhãn dự đoán\n","            _, predicted_labels = torch.max(outputs, dim=1)\n","            correct_predictions += (predicted_labels == labels).sum().item()\n","            total_samples += labels.size(0)\n","\n","    avg_loss = total_loss / len(test_dataloader)\n","    accuracy = correct_predictions / total_samples\n","\n","    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n","    return avg_loss, accuracy\n","\n","# Kiểm thử mô hình trên tập dữ liệu kiểm thử\n","test_loss, test_accuracy = test_model(model, test_dataloader, criterion)\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5742446,"sourceId":9448093,"sourceType":"datasetVersion"},{"datasetId":5888462,"sourceId":9642632,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
